# Deep Q-Learning with different embeddings for 2048
###### This repository contains my Deep Q-Learning implementation that learns how to play the mobile game 2048.

The agent is based on the Deep Q-Learning architercture ([link](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf)) which tries to determine which direction to swipe to at the given state.
The main concern, however, is the representation of the game since the game consists a 4x4 table and each tile can attain 17 different states. The most straight-forward solution is then to store the states in a 17x4x4 array in binary representation, but it is rather sparse to feed into a neural network that leads to slow convergence.

In order to reduce the sparsity of this matrix, I have implemented the agent with three simple representation;
* the simple binary array
* a linear embedding that takes values between zero and one in an increasing order
* an embedding that uses three layers with interpolation values of sine, cosine and a logit function

The basic approach is to use a convolutional network as interpret the embeddings as channels, but I have added one more option a flat embeddings which flatten the binary array and uses simple feed-forward network instead.

> game.py

This file contains the functions to play the game. The game can be played via two variables a 4x4 numpy array to store the current state and a score variable related to the state. The actions are defined as the integers 0,1,2,3 in a clockwise manner starting at 12 o'clock.

> shared_functions.py

This file contains the reshaping functions that convert the 4x4 array into a suitable input for the neural networks. Also, it contains the functions to initialize the convolutional and feed-forward networks and the functions for the rewards and trainings.

> random_pre_games.py pre_game_num output

It generates the given number of random games and store it at the given hdf5 output file.

> pre_train.py type id random_games

This file initialize a neural network of the given type and trains it for the states given in the random_games file (possibly generated by the random_pre_games.py script)

> main_train.py steps input_model

It trains further a pre-trained input model for the given number of steps. In this stage, it uses an epsilon-greedy exploration that decreases as the training proceeds.

> embedding_2048.py

This file contains the implementation of the word-embedding like approach. It is a network that combines the continuous bag-of-words and the skip-gram models. Its input is 32 vectors from the two neighbour states (one before and one after) and it predicts 16 output vectors which corresponds to the current state.

> embed_model.py epochs embedding_size output_path

This file contains the implementation of the word-embedding based Deep Q-Network. It is similar to the model.py but it has an embedding layer first on the 20x4x4 array that reduces the number of channels. The agent runs a given number of random games and then learns the basic embedding then it updates it after given timesteps.

Due to the lack of computational power large-scale experiments have not yet been conducted, but as soon as I am granted with the chance to run it on a GPU-cluster I will update this repository with the results.
